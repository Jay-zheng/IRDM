{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is config for HomeDepot Project\n",
    "Competition: HomeDepot Search Relevance\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "DATA_DIR= \"/Users/Hermione/MasterUCL/Info retrieval and data mining/coursework/dataset\"\n",
    "PROCESSINGTEXT_DIR= \"/Users/Hermione/MasterUCL/Info retrieval and data mining/coursework/processing_text\"\n",
    "FEATURES_DIR= \"/Users/Hermione/MasterUCL/Info retrieval and data mining/coursework/features\"\n",
    "SAVEDMODELS_DIR= \"/Users/Hermione/MasterUCL/Info retrieval and data mining/coursework/saved_models\"\n",
    "MODELS_DIR= \"/Users/Hermione/MasterUCL/Info retrieval and data mining/coursework/models\"\n",
    "MODELSENSEMBLE_DIR= \"/Users/Hermione/MasterUCL/Info retrieval and data mining/coursework/models_ensemble\"\n",
    "FEATURESETS_DIR=\"/Users/Hermione/MasterUCL/Info retrieval and data mining/coursework/feature_sets\"\n",
    "\n",
    "\n",
    "if not os.path.exists(PROCESSINGTEXT_DIR):\n",
    "    os.mkdir(PROCESSINGTEXT_DIR)\n",
    "if not os.path.exists(FEATURES_DIR):\n",
    "    os.mkdir(FEATURES_DIR)\n",
    "if not os.path.exists(SAVEDMODELS_DIR):\n",
    "    os.mkdir(SAVEDMODELS_DIR)\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "if not os.path.exists(MODELSENSEMBLE_DIR):\n",
    "    os.mkdir(MODELSENSEMBLE_DIR)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english')\n",
    "stoplist.append('till')  # add 'till' to stoplist\n",
    "\n",
    "# 'can' also might mean 'a container' like in 'trash can' \n",
    "# so we create a separate stop list without 'can' to be used for query and product title\n",
    "stoplist_wo_can=stoplist[:]\n",
    "stoplist_wo_can.remove('can')\n",
    "\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "import difflib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_parser(s):\n",
    "    s = re.sub('&amp;', '&', s)\n",
    "    s = re.sub('&nbsp;', '', s)\n",
    "    s = re.sub('&#39;', '', s)\n",
    "    s = s.replace(\"-\",\" \")\n",
    "    s = s.replace(\"+\",\" \")\n",
    "    s = re.sub(r'(?<=[a-zA-Z])\\/(?=[a-zA-Z])', ' ', s)\n",
    "    s = re.sub(r'(?<=\\))(?=[a-zA-Z0-9])', ' ', s) # add space between parentheses and letters\n",
    "    s = re.sub(r'(?<=[a-zA-Z0-9])(?=\\()', ' ', s) # add space between parentheses and letters\n",
    "    s = re.sub(r'(?<=[a-zA-Z][\\.\\,])(?=[a-zA-Z])', ' ', s) # add space after dot or colon between letters\n",
    "    s = re.sub('[^a-zA-Z0-9\\n\\ ]', '', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### PREPROCESSING ######################\n",
    "\n",
    "\n",
    "### load train and test ###################\n",
    "df_train = pd.read_csv(DATA_DIR+'/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv(DATA_DIR+'/test.csv', encoding=\"ISO-8859-1\")\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "### load product attributes ###############\n",
    "df_attr = pd.read_csv(DATA_DIR+'/attributes.csv', encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find unique brands from the attributes file\n",
    "### for a few product_uids there are at least two different names in \"MFG Brand Name\"\n",
    "### in such cases we keep only one of the names\n",
    "df_all = pd.merge(df_all, df_attr[df_attr['name']==\"MFG Brand Name\"][['product_uid','value']], how='left', on='product_uid')\n",
    "df_all['brand']=df_all['value'].fillna(\"\").map(lambda x: x.encode(\"utf-8\"))\n",
    "df_all=df_all.drop('value',axis=1)\n",
    "#df_all= df_all.decode('GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458  words from brands in add_space_stop_list\n",
      "1722  total words from brands and product titles in add_space_stop_list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create a list of words with lowercase and uppercase letters \n",
    "### Examples: 'InSinkErator', 'EpoxyShield'\n",
    "### They are words from brand names or words from product title.\n",
    "### The dict is used to correct product description which contins concatenated \n",
    "### lines of text without separators : \n",
    "### ---View lawn edgings and brick/ paver edgingsUtility stakes can be used for many purposes---\n",
    "### Here we need to replace 'edgingsUtility' with 'edgings utility'. \n",
    "### But we don't need to replace 'InSinkErator' with 'in sink erator'\n",
    "add_space_stop_list=[]\n",
    "uniq_brands=list(set(list(df_all['brand'])))\n",
    "for i in range(0,len(uniq_brands)):\n",
    "    uniq_brand = uniq_brands[i].decode(\"utf-8\") \n",
    "    uniq_brands[i]=simple_parser(uniq_brand)\n",
    "    if re.search(r'[a-z][A-Z][a-z]',uniq_brands[i])!=None:\n",
    "        for word in uniq_brands[i].split():\n",
    "            if re.search(r'[a-z][A-Z][a-z]',word)!=None:\n",
    "                add_space_stop_list.append(word.lower())\n",
    "add_space_stop_list=list(set(add_space_stop_list))      \n",
    "print(len(add_space_stop_list),\" words from brands in add_space_stop_list\")\n",
    "                \n",
    "uniq_titles=list(set(list(df_all['product_title'])))\n",
    "for i in range(0,len(uniq_titles)):\n",
    "    uniq_title = uniq_titles[i]\n",
    "    uniq_titles[i]=simple_parser(uniq_title)\n",
    "    if re.search(r'[a-z][A-Z][a-z]',uniq_titles[i])!=None:\n",
    "        for word in uniq_titles[i].split():\n",
    "            if re.search(r'[a-z][A-Z][a-z]',word)!=None:\n",
    "                add_space_stop_list.append(word.lower())    \n",
    "add_space_stop_list=list(set(add_space_stop_list))      \n",
    "print(len(add_space_stop_list) ,\" total words from brands and product titles in add_space_stop_list\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_dict import *\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x: google_dict[x] if x in google_dict.keys() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_word_in_string(word, s):\n",
    "    return word in s.split()\n",
    "\n",
    "\n",
    "def create_bigrams(s):\n",
    "    lst = [word for word in s.split() if len(re.sub('[^0-9]', '', word)) == 0 and len(word) > 2]\n",
    "    output = \"\"\n",
    "    i = 0\n",
    "    if len(lst) >= 2:\n",
    "        while i < len(lst) - 1:\n",
    "            output += \" \" + lst[i] + \"_\" + lst[i + 1]\n",
    "            i += 1\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['product_title_simpleparsed'] = df_all['product_title'].map(lambda x: simple_parser(x).lower())\n",
    "df_all['search_term_simpleparsed'] = df_all['search_term'].map(lambda x: simple_parser(x).lower())\n",
    "\n",
    "str_title = \" \".join(list(df_all['product_title'].map(lambda x: simple_parser(x).lower())))\n",
    "str_query = \" \".join(list(df_all['search_term'].map(lambda x: simple_parser(x).lower())))\n",
    "\n",
    "# create bigrams\n",
    "bigrams_str_title = \" \".join(list(df_all['product_title'].map(lambda x: create_bigrams(simple_parser(x).lower()))))\n",
    "bigrams_set = set(bigrams_str_title.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### count word frequencies for query and product title\n",
    "my_dict = {}\n",
    "str1 = str_title + \" \" + str_query\n",
    "for word in list(set(list(str1.split()))):\n",
    "    my_dict[word] = {\"title\": 0, \"query\": 0, 'word': word}\n",
    "for word in str_title.split():\n",
    "    my_dict[word][\"title\"] += 1\n",
    "for word in str_query.split():\n",
    "    my_dict[word][\"query\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Return ratio and scaled ratio from difflib.SequenceMatcher()\n",
    "\n",
    "def seq_matcher(s1, s2):\n",
    "    seq = difflib.SequenceMatcher(None, s1, s2)\n",
    "    rt = round(seq.ratio(), 7)\n",
    "    l1 = len(s1)\n",
    "    l2 = len(s2)\n",
    "    if len(s1) == 0 or len(s2) == 0:\n",
    "        rt = 0\n",
    "        rt_scaled = 0\n",
    "    else:\n",
    "        rt_scaled = round(rt * max(l1, l2) / min(l1, l2), 7)\n",
    "    return rt, rt_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Process words without digits\n",
    "### Potential errors: words that appear only in query\n",
    "### Correct words: 5 or more times in product_title\n",
    "errors_dict = {}\n",
    "correct_dict = {}\n",
    "for word in my_dict.keys():\n",
    "    if len(word) >= 3 and len(re.sub('[^0-9]', '', word)) == 0:\n",
    "        if my_dict[word][\"title\"] == 0:\n",
    "            if len(wn.synsets(word)) > 0 \\\n",
    "                    or (word.endswith('s') and (word[:-1] in my_dict.keys()) and my_dict[word[:-1]][\"title\"] > 0) \\\n",
    "                    or (word[-1] != 's' and (word + 's' in my_dict.keys()) and my_dict[word + 's'][\"title\"] > 0):\n",
    "                1\n",
    "            else:\n",
    "                errors_dict[word] = my_dict[word]\n",
    "        elif my_dict[word][\"title\"] >= 5:\n",
    "            correct_dict[word] = my_dict[word]\n",
    "\n",
    "### for each error word try finding a good match in bigrams, matched products, all products\n",
    "cnt = 0\n",
    "NN = len(errors_dict.keys())\n",
    "t0 = time()\n",
    "for i in range(0, len(errors_dict.keys())):\n",
    "    word = sorted(errors_dict.keys())[i]\n",
    "    cnt += 1\n",
    "    lst = []\n",
    "    lst_tuple = []\n",
    "    suggested = False\n",
    "    suggested_word = \"\"\n",
    "    rt_max = 0\n",
    "\n",
    "    # if only one word in query, use be more selective in choosing a correction\n",
    "    min_query_len = min(df_all['search_term_simpleparsed'][\n",
    "                            df_all['search_term_simpleparsed'].map(lambda x: is_word_in_string(word, x))].map(\n",
    "        lambda x: len(x.split())))\n",
    "    delta = 0.05 * int(min_query_len < 2)\n",
    "\n",
    "    words_from_matched_titles = [item for item in \\\n",
    "                                 \" \".join(list(set(df_all['product_title_simpleparsed'][\n",
    "                                                       df_all['search_term_simpleparsed'].map(\n",
    "                                                           lambda x: is_word_in_string(word, x))]))).split() \\\n",
    "                                 if len(item) > 2 and len(re.sub('[^0-9]', '', item)) == 0]\n",
    "    words_from_matched_titles = list(set(words_from_matched_titles))\n",
    "    words_from_matched_titles.sort()\n",
    "\n",
    "    source = \"\"\n",
    "    for bigram in bigrams_set:\n",
    "        if bigram.replace(\"_\", \"\") == word:\n",
    "            suggested = True\n",
    "            suggested_word = bigram.replace(\"_\", \" \")\n",
    "            source = \"from bigrams\"\n",
    "\n",
    "    if source == \"\":\n",
    "        for correct_word in words_from_matched_titles:\n",
    "            rt, rt_scaled = seq_matcher(word, correct_word)\n",
    "            # print correct_word, rt,rt_scaled\n",
    "\n",
    "            if rt > 0.75 + delta or (len(word) < 6 and rt > 0.68 + delta):\n",
    "                lst.append(correct_word)\n",
    "                lst_tuple.append((correct_word, my_dict[correct_word][\"title\"]))\n",
    "                if rt > rt_max:\n",
    "                    rt_max = rt\n",
    "                    suggested = True\n",
    "                    source = \"from matched products\"\n",
    "                    suggested_word = correct_word\n",
    "                elif rt == rt_max and seq_matcher(\"\".join(sorted(word)), \"\".join(sorted(correct_word)))[0] > \\\n",
    "                        seq_matcher(\"\".join(sorted(word)), \"\".join(sorted(suggested_word)))[0]:\n",
    "                    suggested_word = correct_word\n",
    "                elif rt == rt_max:\n",
    "                    suggested = False\n",
    "                    source = \"\"\n",
    "\n",
    "    if source == \"\" and len(lst) == 0:\n",
    "        source = \"from all products\"\n",
    "        for correct_word in correct_dict.keys():\n",
    "            rt, rt_scaled = seq_matcher(word, correct_word)\n",
    "            # print correct_word, rt,rt_scaled\n",
    "            if correct_dict[correct_word][\"title\"] > 10 and (rt > 0.8 + delta or (len(word) < 6 and rt > 0.73 + delta)):\n",
    "                # print correct_word, rt,rt_scaled\n",
    "                lst.append(correct_word)\n",
    "                lst_tuple.append((correct_word, correct_dict[correct_word][\"title\"]))\n",
    "                if rt > rt_max:\n",
    "                    rt_max = rt\n",
    "                    suggested = True\n",
    "                    suggested_word = correct_word\n",
    "                elif rt == rt_max and seq_matcher(\"\".join(sorted(word)), \"\".join(sorted(correct_word)))[0] > \\\n",
    "                        seq_matcher(\"\".join(sorted(word)), \"\".join(sorted(suggested_word)))[0]:\n",
    "                    suggested_word = correct_word\n",
    "                elif rt == rt_max:\n",
    "                    suggested = False\n",
    "\n",
    "    if suggested == True:\n",
    "        errors_dict[word][\"suggestion\"] = suggested_word\n",
    "        errors_dict[word][\"others\"] = lst_tuple\n",
    "        errors_dict[word][\"source\"] = source\n",
    "    else:\n",
    "        errors_dict[word][\"suggestion\"] = \"\"\n",
    "        errors_dict[word][\"others\"] = lst_tuple\n",
    "        errors_dict[word][\"source\"] = source\n",
    "        # print(cnt, word, errors_dict[word][\"query\"], errors_dict[word][\"suggestion\"], source, errors_dict[word][\"others\"])\n",
    "        # if (cnt % 20)==0:\n",
    "        #    print cnt, \" out of \", NN, \"; \", round((time()-t0),1) ,' sec'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building spell checker time: 10.6 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in my_dict.keys():\n",
    "    if my_dict[word]['query'] > 0 and my_dict[word]['title'] == 0 \\\n",
    "            and len(re.sub('[^0-9]', '', word)) != 0 and len(re.sub('[^a-z]', '', word)) != 0:\n",
    "        srch = re.search(r'(?<=^)[a-z][a-z][a-z]+(?=[0-9])', word)\n",
    "        if srch != None and len(wn.synsets(srch.group(0))) > 0 \\\n",
    "                and len(re.sub('[^aeiou]', '', word)) > 0 and word[-1] in '0123456789':\n",
    "            errors_dict[word] = my_dict[word]\n",
    "            errors_dict[word][\"source\"] = \"added space before digit\"\n",
    "            errors_dict[word][\"suggestion\"] = re.sub(r'(?<=^)' + srch.group(0) + r'(?=[a-zA-Z0-9])',\n",
    "                                                     srch.group(0) + ' ', word)\n",
    "            # print word, re.sub(r'(?<=^)'+srch.group(0)+r'(?=[a-zA-Z0-9])',srch.group(0)+' ',word)\n",
    "\n",
    "### save dictionary\n",
    "corrections_df = pd.DataFrame(errors_dict).transpose()\n",
    "#corrections_df.to_csv(PROCESSINGTEXT_DIR + \"/automatically_generated_word_corrections.csv\")\n",
    "\n",
    "print('building spell checker time:', round((time() - t0) / 60, 1), 'minutes\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are many non-unique queries and products. To save time, in some cases we processed only unique entries.\n",
    "The following function applies str_parser() function to unique entries only.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def col_parser(clmn, automatic_spell_check_dict={}, remove_from_brackets=False, parse_material=False,\n",
    "               add_space_stop_list=[]):\n",
    "    t0 = time()\n",
    "    aa = list(set(list(clmn)))\n",
    "    my_dict = {}\n",
    "    for i in range(0, len(aa)):\n",
    "        my_dict[aa[i]] = str_parser(aa[i], automatic_spell_check_dict=automatic_spell_check_dict,\n",
    "                                    remove_from_brackets=remove_from_brackets, \\\n",
    "                                    parse_material=parse_material, add_space_stop_list=add_space_stop_list)\n",
    "        if (i % 10000) == 0:\n",
    "            print\n",
    "            \"parsed \" + str(i) + \" out of \" + str(len(aa)) + \" unique values; \" + str(\n",
    "                round((time() - t0) / 60, 1)) + \" minutes\"\n",
    "    return clmn.map(lambda x: my_dict[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def str_parser(s, automatic_spell_check_dict={}, remove_from_brackets=False, parse_material=False,\n",
    "               add_space_stop_list=[]):\n",
    "    # the following three replacements are shared on the forum\n",
    "    s = s.replace(\"craftsm,an\", \"craftsman\")\n",
    "    s = re.sub(r'depot.com/search=', '', s)\n",
    "    s = re.sub(r'pilers,needlenose', 'pliers, needle nose', s)\n",
    "\n",
    "    s = re.sub(r'\\bmr.', 'mr ', s)\n",
    "    s = re.sub(r'&amp;', '&', s)\n",
    "    s = re.sub('&nbsp;', '', s)\n",
    "    s = re.sub('&#39;', '', s)\n",
    "    s = re.sub(r'(?<=[0-9]),[\\ ]*(?=[0-9])', '', s)\n",
    "    s = s.replace(\";\", \".\")\n",
    "    s = s.replace(\",\", \".\")\n",
    "    s = s.replace(\":\", \". \")\n",
    "    s = s.replace(\"+\", \" \")\n",
    "    s = re.sub(r'\\bU.S.', 'US ', s)\n",
    "    s = s.replace(\" W x \", \" \")\n",
    "    s = s.replace(\" H x \", \" \")\n",
    "    s = re.sub(' [\\#]\\d+[\\-\\d]*[\\,]*', '', s)\n",
    "    s = re.sub('(?<=[0-9\\%])(?=[A-Z][a-z])', '. ', s)  # add dot between number and cap letter\n",
    "    s = re.sub(r'(?<=\\))(?=[a-zA-Z0-9])', ' ', s)  # add space between parentheses and letters\n",
    "    s = re.sub(r'(?<=[a-zA-Z0-9])(?=\\()', ' ', s)  # add space between parentheses and letters\n",
    "\n",
    "    if parse_material:\n",
    "        replace_dict = {'Medium Density Fiberboard (MDF)': 'mdf', 'High Density Fiberboard (HDF)': 'hdf', \\\n",
    "                        'Fibre Reinforced Polymer (FRP)': 'frp', 'Acrylonitrile Butadiene Styrene (ABS)': 'abs', \\\n",
    "                        'Cross-Linked Polyethylene (PEX)': 'pex', 'Chlorinated Poly Vinyl Chloride (CPVC)': 'cpvc', \\\n",
    "                        'PVC (vinyl)': 'pvc', 'Thermoplastic rubber (TPR)': 'tpr', 'Poly Lactic Acid (PLA)': 'pla', \\\n",
    "                        '100% Polyester': 'polyester', '100% UV Olefin': 'olefin',\n",
    "                        '100% BCF Polypropylene': 'polypropylene', \\\n",
    "                        '100% PVC': 'pvc'}\n",
    "\n",
    "        if s in replace_dict.keys():\n",
    "            s = replace_dict[s]\n",
    "\n",
    "    s = re.sub('[^a-zA-Z0-9\\n\\ \\%\\$\\-\\#\\@\\&\\/\\.\\'\\*\\(\\)]', ' ', s)\n",
    "    s = \" \".join(s.split())\n",
    "\n",
    "    s = s.replace(\"-\", \" \")\n",
    "\n",
    "    if len(add_space_stop_list) > 0:\n",
    "        s = \" \".join(\n",
    "            [re.sub('(?<=[a-z])(?=[A-Z][a-z\\ ])', '. ', word) if word.lower() not in add_space_stop_list else word for\n",
    "             word in s.split()])\n",
    "\n",
    "    s = s.lower()\n",
    "    s = re.sub('\\.(?=[a-z])', '. ', s)  # dots before words -> replace with spaces\n",
    "    # s = re.sub('(?<=[a-z])(?=[A-Z][a-z\\ ])', ' ', s) # add space if uppercase after lowercase\n",
    "    s = re.sub('(?<=[a-z][a-z][a-z])(?=[0-9])', ' ', s)  # add cpase if number after at least three letters\n",
    "    ##s = re.sub('(?<=[a-zA-Z])\\.(?=\\ |$)', '', s) #remove dots at the end of string\n",
    "    # s = re.sub('(?<=[0-9])\\.(?=\\ |$)', '', s) # dot after digit before space\n",
    "    s = re.sub('^\\.\\ ', '', s)  # dot at the beginning before space\n",
    "\n",
    "    if len(automatic_spell_check_dict.keys()) > 0:\n",
    "        s = spell_correction(s, automatic_spell_check_dict=automatic_spell_check_dict)\n",
    "\n",
    "    if remove_from_brackets == True:\n",
    "        s = re.sub('(?<=\\()[a-zA-Z0-9\\n\\ \\%\\$\\-\\#\\@\\&\\/\\.\\'\\*\\(\\)]*(?=\\))', '', s)\n",
    "    else:\n",
    "        s = s.replace(\" (\", \". \")\n",
    "        s = re.sub('(?<=[a-zA-Z0-9\\%\\$])\\(', '. ', s)\n",
    "        s = s.replace(\" )\", \". \")\n",
    "        s = s.replace(\")\", \". \")\n",
    "        s = s.replace(\"  \", \" \")\n",
    "        s = re.sub('\\ \\.', '\\.', s)\n",
    "\n",
    "    #######s = re.sub('(?<=[0-9\\%])(?=[a-wyz])', ' ', s) # add space between number and text (except letter x)\n",
    "    # s = re.sub('(?<=[a-zA-Z])-(?=[a-zA-Z])', ' ', s) # replace '-' in words with space\n",
    "    s = s.replace(\"at&t\", \"att\")\n",
    "    s = s.replace(\"&\", \" and \")\n",
    "    s = s.replace(\"*\", \" x \")\n",
    "    s = re.sub('(?<=[a-z\\ ])\\/(?=[a-z\\ ])', ' ', s)  # replace \"/\" between words with space\n",
    "    s = re.sub('(?<=[a-z])\\\\\\\\(?=[a-z])', ' ', s)  # replace \"/\" between words with space\n",
    "    s = s.replace(\"  \", \" \")\n",
    "    s = s.replace(\"  \", \" \")\n",
    "\n",
    "    # s=re.sub('(?<=\\ [a-ux-z])\\ (?=[0-9])', '', s)   #remove spaces\n",
    "    # s=re.sub('(?<=^[a-z])\\ (?=[0-9])', '', s)   #remove spaces\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### thesaurus replacement in all vars\n",
    "    s = replace_in_parser(s)\n",
    "\n",
    "    s = re.sub('half(?=\\ inch)', '1/2', s)\n",
    "    s = re.sub('\\ba half\\b', '1/2', s)\n",
    "    # s = re.sub('half\\ ', 'half-', s)\n",
    "\n",
    "    s = re.sub(r'(?<=\\')s\\b', '', s)\n",
    "    s = re.sub('(?<=[0-9])\\'\\'', ' in ', s)\n",
    "    s = re.sub('(?<=[0-9])\\'', ' in ', s)\n",
    "\n",
    "    s = re.sub(r'(?<=[0-9])[\\ ]*inch[es]*\\b', '-in ', s)\n",
    "    s = re.sub(r'(?<=[0-9])[\\ ]*in\\b', '-in ', s)\n",
    "\n",
    "    s = re.sub(r'(?<=[0-9])[\\-|\\ ]*feet[s]*\\b', '-ft ', s)\n",
    "    s = re.sub(r'(?<=[0-9])[\\ ]*foot[s]*\\b', '-ft ', s)\n",
    "    s = re.sub(r'(?<=[0-9])[\\ ]*ft[x]*\\b', '-ft ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*volt[s]*(?=\\ |$|\\.)', '-V ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*v(?=\\ |$|\\.)', '-V ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*wat[t]*[s]*(?=\\ |$|\\.)', '-W ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*w(?=\\ |$|\\.)', '-W ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*kilo[\\ ]*watt[s]*(?=\\ |$|\\.)', '-KW ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*kw(?=\\ |$|\\.)', '-KW ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*amp[s]*(?=\\ |$|\\.)', '-A ', s)\n",
    "    # s = re.sub('(?<=[0-9]) a(?=\\ |$|\\.)', '-A. ', s)\n",
    "    s = re.sub('(?<=[0-9])a(?=\\ |$|\\.)', '-A ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*gallon[s]*(?=\\ |$|\\.)', '-gal ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*gal(?=\\ |$|\\.)', '-gal ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*pound[s]*(?=\\ |$|\\.)', '-lb ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*lb[s]*(?=\\ |$|\\.)', '-lb ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*mi[l]+imet[er]*[s]*(?=\\ |$|\\.)', '-mm ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*mm(?=\\ |$|\\.)', '-mm ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*centimeter[s]*(?=\\ |$|\\.)', '-cm ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*cm(?=\\ |$|\\.)', '-cm ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*ounce[s]*(?=\\ |$|\\.)', '-oz ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*oz(?=\\ |$|\\.)', '-oz ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*liter[s]*(?=\\ |$|\\.)', '-L ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*litre[s]*(?=\\ |$|\\.)', '-L ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*l(?=\\ |$|\\.)', '-L. ', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*square feet[s]*(?=\\ |$|\\.)', '-sqft ', s)\n",
    "    s = re.sub('(?<=[0-9])square feet[s]*(?=\\ |$|\\.)', '-sqft ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*sq[\\ |\\.|\\.\\ ]*ft(?=\\ |$|\\.)', '-sqft ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*sq. ft(?=\\ |$|\\.)', '-sqft', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*sq.ft(?=\\ |$|\\.)', '-sqft', s)\n",
    "\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*cubic f[e]*t[s]*(?=\\ |$|\\.)', '-cuft ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*cu[\\ |\\.|\\.\\ ]*ft(?=\\ |$|\\.)', '-cuft ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*cu[\\.]*[\\ ]*ft(?=\\ |$|\\.)', '-cuft', s)\n",
    "\n",
    "    # remove 'x'\n",
    "    s = re.sub('(?<=[0-9]) x (?=[0-9])', '-X ', s)\n",
    "    s = re.sub('(?<=[0-9])x (?=[0-9])', '-X ', s)\n",
    "    s = re.sub('(?<=[0-9]) x(?=[0-9])', '-X ', s)\n",
    "    s = re.sub('(?<=[0-9])x(?=[0-9])', '-X ', s)\n",
    "\n",
    "    # s=s.replace(\"..\",\".\")\n",
    "    s = s.replace(\"\\n\", \" \")\n",
    "    s = s.replace(\"  \", \" \")\n",
    "\n",
    "    words = s.split()\n",
    "\n",
    "    if s.find(\"-X\") >= 0:\n",
    "        for cnt in range(0, len(words) - 1):\n",
    "            if words[cnt].find(\"-X\") >= 0:\n",
    "                if words[cnt + 1].find(\"-X\") and cnt < len(words) - 2:\n",
    "                    cntAdd = 2\n",
    "                else:\n",
    "                    cntAdd = 1\n",
    "                to_replace = re.search(r'(?<=[0-9]\\-)\\w+\\b', words[cnt + cntAdd])\n",
    "                if not (to_replace == None):\n",
    "                    words[cnt] = words[cnt].replace(\"-X\", \"-\" + to_replace.group(0) + \"\")\n",
    "                else:\n",
    "                    words[cnt] = words[cnt].replace(\"-X\", \"x\")\n",
    "    s = \" \".join([word for word in words])\n",
    "\n",
    "    s = re.sub('[^a-zA-Z0-9\\ \\%\\$\\-\\@\\&\\/\\.]', '', s)  # remove \"'\" and \"\\n\" and \"#\" and characters\n",
    "    ##s = re.sub('(?<=[a-zA-Z])[\\.|\\/](?=\\ |$)', '', s) #remove dots at the end of string\n",
    "    s = re.sub('(?<=[0-9])x(?=\\ |$)', '', s)  # remove\n",
    "    s = re.sub('(?<=[\\ ])x(?=[0-9])', '', s)  # remove\n",
    "    s = re.sub('(?<=^)x(?=[0-9])', '', s)\n",
    "    # s = re.sub('[\\ ]\\.(?=\\ |$)', '', s) #remove dots\n",
    "    s = s.replace(\"  \", \" \")\n",
    "    s = s.replace(\"..\", \".\")\n",
    "    s = re.sub('\\ \\.', '', s)\n",
    "\n",
    "    s = re.sub('(?<=\\ [ch-hj-np-su-z][a-z])\\ (?=[0-9])', '', s)  # remove spaces\n",
    "    s = re.sub('(?<=^[ch-hj-np-su-z][a-z])\\ (?=[0-9])', '', s)  # remove spaces\n",
    "\n",
    "    s = re.sub('(?<=\\ )\\.(?=[0-9])', '0.', s)\n",
    "    s = re.sub('(?<=^)\\.(?=[0-9])', '0.', s)\n",
    "    return \" \".join([word for word in s.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spell_correction(s, automatic_spell_check_dict={}):\n",
    "    s = s.replace(\"ttt\", \"tt\")\n",
    "    s = s.replace(\"lll\", \"ll\")\n",
    "    s = s.replace(\"nnn\", \"nn\")\n",
    "    s = s.replace(\"rrr\", \"rr\")\n",
    "    s = s.replace(\"sss\", \"ss\")\n",
    "    s = s.replace(\"zzz\", \"zz\")\n",
    "    s = s.replace(\"ccc\", \"cc\")\n",
    "    s = s.replace(\"eee\", \"ee\")\n",
    "\n",
    "    s = s.replace(\"hinges with pishinges with pins\", \"hinges with pins\")\n",
    "    s = s.replace(\"virtue usa\", \"virtu usa\")\n",
    "    s = re.sub('outdoor(?=[a-rt-z])', 'outdoor ', s)\n",
    "    s = re.sub(r'\\bdim able\\b', \"dimmable\", s)\n",
    "    s = re.sub(r'\\blink able\\b', \"linkable\", s)\n",
    "    s = re.sub(r'\\bm aple\\b', \"maple\", s)\n",
    "    s = s.replace(\"aire acondicionado\", \"air conditioner\")\n",
    "    s = s.replace(\"borsh in dishwasher\", \"bosch dishwasher\")\n",
    "    s = re.sub(r'\\bapt size\\b', 'appartment size', s)\n",
    "    s = re.sub(r'\\barm[e|o]r max\\b', 'armormax', s)\n",
    "    s = re.sub(r' ss ', ' stainless steel ', s)\n",
    "    s = re.sub(r'\\bmay tag\\b', 'maytag', s)\n",
    "    s = re.sub(r'\\bback blash\\b', 'backsplash', s)\n",
    "    s = re.sub(r'\\bbum boo\\b', 'bamboo', s)\n",
    "    s = re.sub(r'(?<=[0-9] )but\\b', 'btu', s)\n",
    "    s = re.sub(r'\\bcharbroi l\\b', 'charbroil', s)\n",
    "    s = re.sub(r'\\bair cond[it]*\\b', 'air conditioner', s)\n",
    "    s = re.sub(r'\\bscrew conn\\b', 'screw connector', s)\n",
    "    s = re.sub(r'\\bblack decker\\b', 'black and decker', s)\n",
    "    s = re.sub(r'\\bchristmas din\\b', 'christmas dinosaur', s)\n",
    "    s = re.sub(r'\\bdoug fir\\b', 'douglas fir', s)\n",
    "    s = re.sub(r'\\belephant ear\\b', 'elephant ears', s)\n",
    "    s = re.sub(r'\\bt emp gauge\\b', 'temperature gauge', s)\n",
    "    s = re.sub(r'\\bsika felx\\b', 'sikaflex', s)\n",
    "    s = re.sub(r'\\bsquare d\\b', 'squared', s)\n",
    "    s = re.sub(r'\\bbehring\\b', 'behr', s)\n",
    "    s = re.sub(r'\\bcam\\b', 'camera', s)\n",
    "    s = re.sub(r'\\bjuke box\\b', 'jukebox', s)\n",
    "    s = re.sub(r'\\brust o leum\\b', 'rust oleum', s)\n",
    "    s = re.sub(r'\\bx mas\\b', 'christmas', s)\n",
    "    s = re.sub(r'\\bmeld wen\\b', 'jeld wen', s)\n",
    "    s = re.sub(r'\\bg e\\b', 'ge', s)\n",
    "    s = re.sub(r'\\bmirr edge\\b', 'mirredge', s)\n",
    "    s = re.sub(r'\\bx ontrol\\b', 'control', s)\n",
    "    s = re.sub(r'\\boutler s\\b', 'outlets', s)\n",
    "    s = re.sub(r'\\bpeep hole', 'peephole', s)\n",
    "    s = re.sub(r'\\bwater pik\\b', 'waterpik', s)\n",
    "    s = re.sub(r'\\bwaterpi k\\b', 'waterpik', s)\n",
    "    s = re.sub(r'\\bplex[iy] glass\\b', 'plexiglass', s)\n",
    "    s = re.sub(r'\\bsheet rock\\b', 'sheetrock', s)\n",
    "    s = re.sub(r'\\bgen purp\\b', 'general purpose', s)\n",
    "    s = re.sub(r'\\bquicker crete\\b', 'quikrete', s)\n",
    "    s = re.sub(r'\\bref ridge\\b', 'refrigerator', s)\n",
    "    s = re.sub(r'\\bshark bite\\b', 'sharkbite', s)\n",
    "    s = re.sub(r'\\buni door\\b', 'unidoor', s)\n",
    "    s = re.sub(r'\\bair tit\\b', 'airtight', s)\n",
    "    s = re.sub(r'\\bde walt\\b', 'dewalt', s)\n",
    "    s = re.sub(r'\\bwaterpi k\\b', 'waterpik', s)\n",
    "    s = re.sub(r'\\bsaw za(ll|w)\\b', 'sawzall', s)\n",
    "    s = re.sub(r'\\blg elec\\b', 'lg', s)\n",
    "    s = re.sub(r'\\bhumming bird\\b', 'hummingbird', s)\n",
    "    s = re.sub(r'\\bde ice(?=r|\\b)', 'deice', s)\n",
    "    s = re.sub(r'\\bliquid nail\\b', 'liquid nails', s)\n",
    "\n",
    "    s = re.sub(r'\\bdeck over\\b', 'deckover', s)\n",
    "    s = re.sub(r'\\bcounter sink(?=s|\\b)', 'countersink', s)\n",
    "    s = re.sub(r'\\bpipes line(?=s|\\b)', 'pipeline', s)\n",
    "    s = re.sub(r'\\bbook case(?=s|\\b)', 'bookcase', s)\n",
    "    s = re.sub(r'\\bwalkie talkie\\b', '2 pair radio', s)\n",
    "    s = re.sub(r'(?<=^)ks\\b', 'kwikset', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*ft(?=[a-z])', 'ft ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*mm(?=[a-z])', 'mm ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*cm(?=[a-z])', 'cm ', s)\n",
    "    s = re.sub('(?<=[0-9])[\\ ]*inch(es)*(?=[a-z])', 'in ', s)\n",
    "\n",
    "    s = re.sub(r'(?<=[1-9]) pac\\b', 'pack', s)\n",
    "\n",
    "    s = re.sub(r'\\bcfl bulbs\\b', 'cfl light bulbs', s)\n",
    "    s = re.sub(r' cfl(?=$)', ' cfl light bulb', s)\n",
    "    s = re.sub(r'candelabra cfl 4 pack', 'candelabra cfl light bulb 4 pack', s)\n",
    "    s = re.sub(r'\\bthhn(?=$|\\ [0-9]|\\ [a-rtuvx-z])', 'thhn wire', s)\n",
    "    s = re.sub(r'\\bplay ground\\b', 'playground', s)\n",
    "    s = re.sub(r'\\bemt\\b', 'emt electrical metallic tube', s)\n",
    "    s = re.sub(r'\\boutdoor dining se\\b', 'outdoor dining set', s)\n",
    "\n",
    "    if \"a/c\" in s:\n",
    "        if ('unit' in s) or ('frost' in s) or ('duct' in s) or ('filt' in s) or ('vent' in s) or ('clean' in s) or (\n",
    "            'vent' in s) or ('portab' in s):\n",
    "            s = s.replace(\"a/c\", \"air conditioner\")\n",
    "        else:\n",
    "            s = s.replace(\"a/c\", \"ac\")\n",
    "\n",
    "    external_data_dict = {'airvents': 'air vents',\n",
    "                          'antivibration': 'anti vibration',\n",
    "                          'autofeeder': 'auto feeder',\n",
    "                          'backbrace': 'back brace',\n",
    "                          'behroil': 'behr oil',\n",
    "                          'behrwooden': 'behr wooden',\n",
    "                          'brownswitch': 'brown switch',\n",
    "                          'byefold': 'bifold',\n",
    "                          'canapu': 'canopy',\n",
    "                          'cleanerakline': 'cleaner alkaline',\n",
    "                          'colared': 'colored',\n",
    "                          'comercialcarpet': 'commercial carpet',\n",
    "                          'dcon': 'd con',\n",
    "                          'doorsmoocher': 'door smoocher',\n",
    "                          'dreme': 'dremel',\n",
    "                          'ecobulb': 'eco bulb',\n",
    "                          'fantdoors': 'fan doors',\n",
    "                          'gallondrywall': 'gallon drywall',\n",
    "                          'geotextile': 'geo textile',\n",
    "                          'hallodoor': 'hallo door',\n",
    "                          'heatgasget': 'heat gasket',\n",
    "                          'ilumination': 'illumination',\n",
    "                          'insol': 'insulation',\n",
    "                          'instock': 'in stock',\n",
    "                          'joisthangers': 'joist hangers',\n",
    "                          'kalkey': 'kelkay',\n",
    "                          'kohlerdrop': 'kohler drop',\n",
    "                          'kti': 'kit',\n",
    "                          'laminet': 'laminate',\n",
    "                          'mandoors': 'main doors',\n",
    "                          'mountspacesaver': 'mount space saver',\n",
    "                          'reffridge': 'refrigerator',\n",
    "                          'refrig': 'refrigerator',\n",
    "                          'reliabilt': 'reliability',\n",
    "                          'replaclacemt': 'replacement',\n",
    "                          'searchgalvanized': 'search galvanized',\n",
    "                          'seedeater': 'seed eater',\n",
    "                          'showerstorage': 'shower storage',\n",
    "                          'straitline': 'straight line',\n",
    "                          'subpumps': 'sub pumps',\n",
    "                          'thromastate': 'thermostat',\n",
    "                          'topsealer': 'top sealer',\n",
    "                          'underlay': 'underlayment',\n",
    "                          'vdk': 'bdk',\n",
    "                          'wallprimer': 'wall primer',\n",
    "                          'weedbgon': 'weed b gon',\n",
    "                          'weedeaters': 'weed eaters',\n",
    "                          'weedwacker': 'weed wacker',\n",
    "                          'wesleyspruce': 'wesley spruce',\n",
    "                          'worklite': 'work light'}\n",
    "\n",
    "    for word in external_data_dict.keys():\n",
    "        s = re.sub(r'\\b' + word + r'\\b', external_data_dict[word], s)\n",
    "\n",
    "    ############ replace words from dict\n",
    "    for word in automatic_spell_check_dict.keys():\n",
    "        s = re.sub(r'\\b' + word + r'\\b', automatic_spell_check_dict[word], s)\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_in_parser(s):\n",
    "    # the first three shared on forum\n",
    "    s = s.replace(\"acccessories\", \"accessories\")\n",
    "    s = re.sub(r'\\bscott\\b', 'scotts', s)  # brand\n",
    "    s = re.sub(r'\\borgainzer\\b', 'organizer', s)\n",
    "\n",
    "    # the others are not shared\n",
    "    s = re.sub(r'\\aluminuum\\b', 'aluminum', s)\n",
    "    s = re.sub(r'\\bgeneral electric', 'ge', s)\n",
    "    s = s.replace(\"adaptor\", \"adapter\")\n",
    "    s = re.sub(r'\\bfibre', 'fiber', s)\n",
    "    s = re.sub(r'\\bbuilt in\\b', 'builtin', s)\n",
    "    s = re.sub(r'\\bshark bite\\b', 'sharkbite', s)\n",
    "    s = re.sub('barbeque', 'barbecue', s)\n",
    "    s = re.sub(r'\\bbbq\\b', 'barbecue', s)\n",
    "    s = re.sub(r'\\bbathroom[s]*\\b', 'bath', s)\n",
    "    s = re.sub(r'\\bberkeley\\b', 'berkley', s)\n",
    "    s = re.sub(r'\\bbookshelves\\b', 'book shelf', s)\n",
    "    s = re.sub(r'\\bbookshelf\\b', 'book shelf', s)\n",
    "    s = re.sub(r'\\bin line ', ' inline ', s)\n",
    "    s = re.sub(r'round up\\b', ' roundup', s)\n",
    "    s = re.sub(r'\\blg electronics\\b', 'lg', s)\n",
    "    s = re.sub(r'\\bhdtv\\b', 'hd tv', s)\n",
    "    s = re.sub(r'black [and ]*decker', 'black and decker', s)\n",
    "    s = re.sub(r'backer board[s]*', 'backerboard', s)\n",
    "    s = re.sub(r'\\bphillips\\b', 'philips', s)\n",
    "    s = re.sub(r'\\bshower head[s]*\\b', 'showerhead', s)\n",
    "    s = re.sub(r'\\bbull nose\\b', 'bullnose', s)\n",
    "    s = re.sub(r'\\bflood light\\b', 'floodlight', s)\n",
    "    s = re.sub(r'\\barrester\\b', 'arrestor', s)\n",
    "    s = re.sub(r'\\bbi fold\\b', 'bifold', s)\n",
    "    s = re.sub(r'\\bfirepit[s]*\\b', 'fire pit', s)\n",
    "    s = re.sub(r'\\bbed bug[s]*\\b', 'bedbug', s)\n",
    "    s = re.sub(r'\\bhook up[s]*\\b', 'hookup', s)\n",
    "    s = re.sub(r'\\bjig saw[s]*\\b', 'jigsaw', s)\n",
    "    s = re.sub(r'\\bspacesav(?=er[s]*|ing)', 'space sav', s)\n",
    "    s = re.sub(r'\\bwall paper', 'wallpaper', s)\n",
    "    s = re.sub(r'\\bphotocell', 'photo cells', s)\n",
    "    s = re.sub(r'\\bplasti dip\\b', 'plastidip', s)\n",
    "    s = re.sub(r'\\bflexi dip\\b', 'flexidip', s)\n",
    "    s = re.sub(r'\\bback splash', 'backsplash', s)\n",
    "    s = re.sub(r'\\bbarstool(?=\\b|s)', 'bar stool', s)\n",
    "    s = re.sub(r'\\blampholder(?=\\b|s)', 'lamp holder', s)\n",
    "    s = re.sub(r'\\brainsuit(?=\\b|s)', 'rain suit', s)\n",
    "    s = re.sub(r'\\bback up\\b', 'backup', s)\n",
    "    s = re.sub(r'\\bwheel barrow', 'wheelbarrow', s)\n",
    "    s = re.sub(r'\\bsaw horse', 'sawhorse', s)\n",
    "    s = re.sub(r'\\bscrew driver', 'screwdriver', s)\n",
    "    s = re.sub(r'\\bnut driver', 'nutdriver', s)\n",
    "    s = re.sub(r'\\bflushmount', 'flush mount', s)\n",
    "    s = re.sub(r'\\bcooktop(?=\\b|s\\b)', 'cook top', s)\n",
    "    s = re.sub(r'\\bcounter top(?=s|\\b)', 'countertop', s)\n",
    "    s = re.sub(r'\\bbacksplash', 'back splash', s)\n",
    "    s = re.sub(r'\\bhandleset', 'handle set', s)\n",
    "    s = re.sub(r'\\bplayset', 'play set', s)\n",
    "    s = re.sub(r'\\bsidesplash', 'side splash', s)\n",
    "    s = re.sub(r'\\bdownlight', 'down light', s)\n",
    "    s = re.sub(r'\\bbackerboard', 'backer board', s)\n",
    "    s = re.sub(r'\\bshoplight', 'shop light', s)\n",
    "    s = re.sub(r'\\bdownspout', 'down spout', s)\n",
    "    s = re.sub(r'\\bpowerhead', 'power head', s)\n",
    "    s = re.sub(r'\\bnightstand', 'night stand', s)\n",
    "    s = re.sub(r'\\bmicro fiber[s]*\\b', 'microfiber', s)\n",
    "    s = re.sub(r'\\bworklight', 'work light', s)\n",
    "    s = re.sub(r'\\blockset', 'lock set', s)\n",
    "    s = re.sub(r'\\bslatwall', 'slat wall', s)\n",
    "    s = re.sub(r'\\btileboard', 'tile board', s)\n",
    "    s = re.sub(r'\\bmoulding', 'molding', s)\n",
    "    s = re.sub(r'\\bdoorstop', 'door stop', s)\n",
    "    s = re.sub(r'\\bwork bench\\b', 'workbench', s)\n",
    "    s = re.sub(r'\\bweed[\\ ]*eater', 'weed trimmer', s)\n",
    "    s = re.sub(r'\\bweed[\\ ]*w[h]*acker', 'weed trimmer', s)\n",
    "    s = re.sub(r'\\bnightlight(?=\\b|s)', 'night light', s)\n",
    "    s = re.sub(r'\\bheadlamp(?=\\b|s)', 'head lamp', s)\n",
    "    s = re.sub(r'\\bfiber board', 'fiberboard', s)\n",
    "    s = re.sub(r'\\bmail box', 'mailbox', s)\n",
    "\n",
    "    replace_material_dict = {'aluminium': 'aluminum',\n",
    "                             'medium density fiberboard': 'mdf',\n",
    "                             'high density fiberboard': 'hdf',\n",
    "                             'fiber reinforced polymer': 'frp',\n",
    "                             'cross linked polyethylene': 'pex',\n",
    "                             'poly vinyl chloride': 'pvc',\n",
    "                             'thermoplastic rubber': 'tpr',\n",
    "                             'poly lactic acid': 'pla',\n",
    "                             'acrylonitrile butadiene styrene': 'abs',\n",
    "                             'chlorinated poly vinyl chloride': 'cpvc'}\n",
    "    for word in replace_material_dict.keys():\n",
    "        if word in s:\n",
    "            s = s.replace(word, replace_material_dict[word])\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_term parsing time: 36.2 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "##### load words for spell checker\n",
    "spell_check_dict = {}\n",
    "for word in errors_dict.keys():\n",
    "    if errors_dict[word]['suggestion'] != \"\":\n",
    "        spell_check_dict[word] = errors_dict[word]['suggestion']\n",
    "\n",
    "\"\"\"\n",
    "spell_check_dict={}\n",
    "with open(PROCESSINGTEXT_DIR+'/automatically_generated_word_corrections.csv') as csvfile:\n",
    "     reader = csv.DictReader(csvfile)\n",
    "     for row in reader:\n",
    "         if row['suggestion']!=\"\":\n",
    "             spell_check_dict[row['word']]=row['suggestion']\n",
    "\"\"\"\n",
    "\n",
    "###############################################\n",
    "### parse query and product title\n",
    "df_all['search_term_parsed'] = col_parser(df_all['search_term'], automatic_spell_check_dict=spell_check_dict, \\\n",
    "                                          add_space_stop_list=[]).map(lambda x: x.encode('utf-8'))\n",
    "df_all['search_term_parsed_wospellcheck'] = col_parser(df_all['search_term'], automatic_spell_check_dict={}, \\\n",
    "                                                       add_space_stop_list=[]).map(lambda x: x.encode('utf-8'))\n",
    "print('search_term parsing time:', round((time() - t0) / 60, 1), 'minutes\\n')\n",
    "\n",
    "t0 = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
